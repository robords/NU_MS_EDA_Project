{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">The EDA project in this course has four main parts to it: <br>\n",
    "    \n",
    "1. Project Proposal\n",
    "2. Phase 1\n",
    "3. Phase 2\n",
    "4. Report\n",
    "\n",
    "This notebook will be used for Project Proposal, Phase 1, and Phase 2. You will have specific questions to answer within this notebook for Project Proposal and Phase 1. You will also continue using this notebook for Phase 2. However, guidance and expectations can be found on Canvas for that assignment. The report is completed outside of this notebook (delivered as a PDF). Detailed instructions for that assignment are provided in Canvas.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"><b><font size=4>Read this before proceeding:</font></b>\n",
    "    \n",
    "1. Review the list of data sets and sources of data to avoid before choosing your data. This list is provided in the instructions for the Project Proposal assignment in Canvas.<br><br>  \n",
    "\n",
    "2. It is expected that when you are asked questions requiring typed explanations you are to use a <b><u>markdown cell</u></b> to type your answers neatly. <b><u><i>Do not provide typed answers to questions as extra comments within your code.</i></u></b> Only provide comments within your code as you normally would, i.e. as needed to explain or remind yourself what each part of the code is doing.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">The intent of this assignment is for you to share your chosen data file(s) with your instructor and provide general information on your goals for the EDA project.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Step 1 (2 pts)</b>: Give a brief <i><u>description</u></i> of the source(s) of your data and include a <i><u>direct link</u></i> to your data.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 1\n",
    "\n",
    "Our source of data is from IMDb (International Movie Database) which is an online database and website for information about movies, television shows, and other streaming content. It is a popular site for people to look up inforamation about ratings, cast, directors, reviews, plot, and any other related information about the content. The 4 datasets we chose to use from their database are the Titles basics, the Ratings data, the crew data, and the name basics. The Titles basics has the name of the media, when and how long it was released or aired, run time, and the genres it belongs to. The Ratings data provides the popularity rating and number of votes of the media title. The crew data provides the IDs for directors and writers. Lastly, the Name basics provides the person's name and primary professions. More information about the data sets can be found here: https://www.imdb.com/interfaces/. The specific data sets for download are found here: https://datasets.imdbws.com/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Step 2 (2 pts)</b>: Briefly explain why you chose this data.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 2\n",
    "\n",
    "Understanding data is a key characteristic to starting statistical analysis. Starting off, our team discussed interests and experiences we might have in common, ultimately agreeing with true crime media. This led us to the IMDb dataset, which we could easily understand given our backgrounds and previous use of the site. Furthermore, we were able to come up with unique questions related to True Crime that we want answered through the analysis of our dataset. While there are analytical reports of IMDb data online, we did not find any analysis related to the questions we came up with. \n",
    "\n",
    "Out of this database, the most relevant datasets that we believe could be useful to answer our questions were title.basics, title.ratings, name.basics and title.crew. There are many other databases such as Rotten Tomatoes or Yahoo! Movies, but IMBD allows us to easily read their tsv data files through the pandas library. This is a simple file format to manipulate and extract to dive deep into coding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Step 3 (1 pt)</b>: Provide a brief overview of your goals for this project.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 3\n",
    "\n",
    "We want to understand what drives the popularity of True Crime media, and media in general over time.  Specifically, we would like to be able to prove or disprove some of the following questions by the end of this project:\n",
    "  * Is it true that True Crime has become more popular over the past five years? \n",
    "  * Has there been an increase in the popularity of documentaries in general?\n",
    "  * Has there been an increase in the volume of documentaries in general?\n",
    "  * Is there a correlation between the air date of a True Crime TV show or movie and it's popularity? \n",
    "  * Are there correlations between the popularity of a genre, specifically True Crime, and the crew?\n",
    "  \n",
    "Given these questions, we'll need to import data from IMDb for the title of the production itself, the crew, the names of the crew and the ratings for that production.  We'll need to download the data, clean it (there are many nulls represented by \"/N\") and join it in order to proceed with answering the above questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Step 4 (1 pt)</b>: Read the data into this notebook.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Import libraries\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import urllib.request  # used to retrieve files from the internet\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "import plotly.offline as py\n",
    "py.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "# set up notebook to display multiple output in one cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_imdb_data(*args):\n",
    "    '''\n",
    "    Input a list of urls from imdb's datasets (https://datasets.imdbws.com/) and return a list of dataframes\n",
    "    '''\n",
    "    df_list = [] #instantiate a list\n",
    "    if len(args):    # check to make sure the user input at least one item in the list\n",
    "        for i in args:                     # for each url:\n",
    "            filename = i.split('/', 3)[-1] # extract a filename from the url (everything after the 3rd \"/\" delimeter)\n",
    "            urllib.request.urlretrieve(i, filename) #retrieve the file from the internet and copy it locally (https://docs.python.org/3/library/urllib.request.html)\n",
    "            df_list.append(pd.read_csv(filename, compression='gzip', sep='\\t', low_memory=False)) \n",
    "            # open the local file as a dataframe and append the dataframe to a list \n",
    "            # low_memory = False will ensure there no mixed types for the columns.  See https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\n",
    "    else:\n",
    "        print('No URLs were passed to read_imbd_data()')\n",
    "    return df_list  #returns a list of dataframes\n",
    "\n",
    "\n",
    "urls = ['https://datasets.imdbws.com/title.ratings.tsv.gz',\n",
    "       'https://datasets.imdbws.com/title.crew.tsv.gz',\n",
    "       'https://datasets.imdbws.com/title.basics.tsv.gz',\n",
    "       'https://datasets.imdbws.com/name.basics.tsv.gz']  # list of urls from imdb\n",
    "\n",
    "df_list = read_imdb_data(*urls) # call the function with the list of urls, of any length, and save the dataframes returned\n",
    "\n",
    "imdb_ratings, imdb_crew, imdb_title_basics, imdb_name = df_list[0], df_list[1], df_list[2], df_list[3] \n",
    "# save each dataframe independently so we can explore them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Step 5 (1 pt)</b>: Inspect the data using the <b>info(&nbsp;)</b>, <b>head(&nbsp;)</b>, and <b>tail(&nbsp;)</b> methods.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the info() method to determine to inspect the variable (column) names, the number of non-null values,\n",
    "#       and the data types for each variable.\n",
    "imdb_title_basics.info()\n",
    "imdb_crew.info()\n",
    "imdb_ratings.info()\n",
    "imdb_name.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the head() method to inspect the first five (or more) rows of the data\n",
    "imdb_title_basics.head()\n",
    "imdb_crew.head()\n",
    "imdb_ratings.head()\n",
    "imdb_name.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the tail() method to inspect the last five (or more) rows of the data\n",
    "imdb_title_basics.tail()\n",
    "imdb_crew.tail()\n",
    "imdb_ratings.tail()\n",
    "imdb_name.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"><b>STOP HERE for your Project Proposal assignment. Submit your (1) original data file(s) along with (2) the completed notebook up to this point, and (3) the html file for grading and approval.</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>Instructor Feedback and Approval (3 pts)</b>: Your instructor will provide feedback in either the cell below this or via Canvas. You can expect one of the following point values for this portion.\n",
    "\n",
    "<b>3 pts</b> - if your project goals and data set are both approved.<br>\n",
    "<b>2 pts</b> - if your data set is approved but changes to your project goals (Step 3) are needed.<br>\n",
    "<b>1 pt</b> - if your project goals are approved but your data set is not approved.<br>\n",
    "<b>0 pts</b> - if neither your data set nor your project goals are approved.<br><br>\n",
    "    \n",
    "<i><u>As needed, follow your instructor's feeback and guidance to get on track for the remaining portions of the EDA project.</u></i>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA Phase 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">The overall goal of this assignment is to take all necessary steps to inspect the quality of your data and prepare the data according to your needs. For information and resources on the process of Exploratory Data Analysis (EDA), you should explore the <b><u>EDA Project Resources Module</u></b> in Canvas.\n",
    "\n",
    "Once you’ve read through the information provided in that module and have a comfortable understanding of EDA using Python, complete steps 6 through 10 listed below to satisfy the requirements for your EDA Phase 1 assignment. **Remember to convert code cells provided to markdown cells for any typed responses to questions.**</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Step 6 (2 pts)</b>: Begin by elaborating in more detail from the previous assignment on why you chose this data?<br>\n",
    "    \n",
    "1. Explain what you hope to learn from this data. \n",
    "2. Do you have a hunch about what this data will reveal? (The answer to this question will be used in the Introduction section of your EDA report.)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hope to learn about the perceived popularity of true crime media in recent years and whether this is driving an increase in true crime documentaries or if there are factors contributing. The sample questions we hope to learn: \n",
    "\n",
    "* Is it true that True Crime has become more popular over time?\n",
    "* Has there been a change in volume of media and/or documentaries in general?\n",
    "    * Could this just be the result of media content increasing overall?\n",
    "    * Could this just be the result of documenatires as a genre increasing overall? \n",
    "* Has popularity of documentaries changed over time? How does this compare to other genres?\n",
    "* Is there a correlation between release date and it's popularity?\n",
    "* Are there correlations between popularity and the crew? For example, is a particular director scoring higher votes and ratings?\n",
    "\n",
    "Our hunch is that there has been both an increase in volume of media overall and in the genre. However, we believe that the genre is growing faster in popularity over time than other genres.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Step 7 (2 pts)</b>: Discuss the popluation and the sample:<br>\n",
    "    \n",
    "1. What is the population being represented by the data you’ve chosen? \n",
    "2. What is the total sample size?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total population of our data is the total number of titles regardless ot type, if they have a rating, or any other attribute provided. It is representative of all streaming content titles on IMDB.\n",
    "\n",
    "The sample size we will focus on for our analysis is just the overall number of unique titles for the overall media types, aka not specific tv epsisodes just the overall tv series, and those that have a signficant number of votes to showcase accurate ratings for popularity.\n",
    "\n",
    "## NEED TO ADD IN FINAL COUNTS\n",
    "directors: 9014736\n",
    "titles: 7634822"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Step 8 (2 pts)</b>: Describe how the data was collected. For example, is this a random sample? Are sampling weights used with the data?</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data that we have researched was provided by IMDB. IMDB is a website that includes many attributes of movies and tv shows. IMBD gathers data through many sources such as movie credits, interviews, press releases, etc. Due to the open nature of the website, a lot of the data is also entered through people in the industry or people visiting the site. To ensure accurate data, IMDB enforces regular quality checks. \n",
    "\n",
    "These datasets are not a random sample and no sample weights were used with the data. \n",
    "\n",
    "\n",
    "Sources:\n",
    "\n",
    "https://help.imdb.com/article/imdb/general-information/where-does-the-information-on-imdb-come-from/GGD7NGF5X3ECFKNN?ref_=helpart_nav_24#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Step 9 (4 pts)</b>: In the Project Proposal assignment you used the info(&nbsp;) method to inspect the variables, their data types, and the number of non-null values. Using that information as a guide, provide definitions of each of your variables and their corresponding data types, i.e. a data dictionary. Also indicate which variables will be used for your purposes.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Should remove directors from media titles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = {'Variable Name': ['tconst','primaryTitle','startYear','genre', 'nconst', 'averageRating', 'numVotes',  'primaryName', 'titleType'],\n",
    "        'Data Type': ['string object','string object','string object','string object', 'string object', 'float', 'integer', 'string object', 'string object'],\n",
    "        'Definition': ['title ID', 'media title', 'Release Year', 'Genre', 'Name ID', 'media rating', 'media votes', 'director''s name', 'type of media']\n",
    "        }\n",
    "\n",
    "title_df = pd.DataFrame(titles, columns = ['Variable Name', 'Data Type', 'Definition'])\n",
    "\n",
    "title_df\n",
    "\n",
    "director = {'Variable Name': ['directorName','directorID','tconst','startYear', 'isTrueCrime', 'averageRating', 'numVotes'],\n",
    "        'Data Type': ['string object','string object','string object','string object', 'boolean', 'float', 'integer'],\n",
    "        'Definition': ['director''s name', 'director''s id', 'title ID', 'Release Year', 'whether the title is true crime or not', 'media rating', 'media votes']\n",
    "        }\n",
    "\n",
    "director_df = pd.DataFrame(director, columns = ['Variable Name', 'Data Type', 'Definition'])\n",
    "\n",
    "director_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Step 10 (10 pts)</b>: For full credit in this problem you'll want to <i><u>take all necessary steps to report on the quality of the data</u></i> and <i><u>clean the data accordingly</u></i>. Some things to consider while doing this are listed below. <b>Depending on your data and goals, there may be additional steps needed than those listed here.</b>\n",
    "    \n",
    "1. Are there rows with missing or inconsistent values? If so, eliminate those rows from your data where appropriate.\n",
    "2. Are there any outliers or duplicate rows? If so, eliminate those rows from your data where appropriate. \n",
    "At each stage of cleaning the data, state how many rows were eliminated.\n",
    "3. Are you using all columns (variables) in the data? If not, are you eliminating those columns?\n",
    "4. Consider some type of visual display such as a boxplot to determine any outliers. Do any outliers need removed? If so, how many were removed?\n",
    "\n",
    "At each stage of cleaning the data, state how many rows were eliminated. <b><u><i>It is good practice to get the shape of the data before and after each step in cleaning the data and add typed explanations (in separate markdown cells) of the steps taken to clean the data.</i></u></b><br></div>\n",
    "    \n",
    "<div class=\"alert alert-block alert-info\">Include the rest of your work below and insert cells where needed.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genre Cleanup - Step 1\n",
    "\n",
    "* Add a column with a boolean datatype where it's True if the genre field contains both 'documentary' or 'crime', case insensitive\n",
    "* Count the number of true crime documentaries in the dataset.\n",
    "* Display the percent of true crime documentaries in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add a column \"IsTrueCrime\"\n",
    "imdb_title_basics['isTrueCrime'] = (imdb_title_basics.genres.str.contains('crime', \n",
    "                flags=re.IGNORECASE, na=False)) & (imdb_title_basics.genres.str.contains('documentary', \n",
    "                flags=re.IGNORECASE, na=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrueCrimeCount = len(imdb_title_basics[imdb_title_basics[\"isTrueCrime\"]])  ## count the number of True items in IsTrueCrime\n",
    "\n",
    "print(f'The total number of titles in the dataset is {len(imdb_title_basics)}.')\n",
    "\n",
    "print(f'''The number of True Crime documentaries in the dataset is {TrueCrimeCount}, which is {round(TrueCrimeCount/len(imdb_title_basics), 3)}% of the total titles.''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Director Cleanup - Step 2\n",
    "\n",
    "We're trying to answer: \"Are there correlations between popularity and the crew? For example, is a particular director scoring higher votes and ratings?\"\n",
    "\n",
    "We considered breaking out the director column into separate fields, so there was only one director per column.  \n",
    "First, we checked whether this was practical by checking for the max number of directors in the imdb_crew dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0 # instantiate a\n",
    "b = 0 # instantiate b\n",
    "\n",
    "for i in imdb_crew.index:  # loop through the crew table's index\n",
    "    if len(imdb_crew.directors[i].split(\",\")) > a: # check to see if the current director count is greater than the last\n",
    "        a, b = len(imdb_crew.directors[i].split(\",\")), i # save the director count and index id to a and b\n",
    "\n",
    "print(f'The title with the most number of directors has an index id of {b} in the crew table and it has {a} directors. See below for more details.')\n",
    "\n",
    "imdb_title_basics[imdb_title_basics.tconst == imdb_crew.tconst[b]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the max number of directors in the dataset is so large (though this could be an outlier), we don't think it's practical to separate them out into separate columns.  Instead we should build a director table consisting of:\n",
    "\n",
    "* directorName (imdb_name.primaryName)\n",
    "* directorID (imdb_crew.directors)\n",
    "* tconst (imdb_crew.tconst)\n",
    "* startYear (imdb_title_basics.startYear)\n",
    "* isTrueCrime (imdb_title_basics.IsTrueCrime)\n",
    "* averageRating (imdb_ratings.averageRating)\n",
    "* numVotes (imdb_ratings.numVotes)\n",
    "\n",
    "With this dataset, we can determine whether the average rating, weighted by the number of votes, is positively correlated with the director.  We will also be able to group by whether the titles are True Crime or not.\n",
    "\n",
    "Next, prepare the data so that we can have a \"director\" dataframe with a single director per row.  For the directors column, we need the string with the director IDs to be a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Convert the directors column, which is currently a string object, to a list and assign the result to a new column\n",
    "print(type(imdb_crew.directors[0])) #confirm the type of the directors column\n",
    "\n",
    "imdb_crew['directors_list'] = imdb_crew['directors'].str.split(',')\n",
    "# split the directors string into a list and create a new column from it\n",
    "\n",
    "imdb_crew.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next \"explode\" the crew data so that each row is an individual director"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>director</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7638146</th>\n",
       "      <td>tt9916850</td>\n",
       "      <td>nm5519454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7638147</th>\n",
       "      <td>tt9916852</td>\n",
       "      <td>nm5519375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7638147</th>\n",
       "      <td>tt9916852</td>\n",
       "      <td>nm5519454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7638148</th>\n",
       "      <td>tt9916856</td>\n",
       "      <td>nm10538645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7638149</th>\n",
       "      <td>tt9916880</td>\n",
       "      <td>nm0996406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            tconst    director\n",
       "7638146  tt9916850   nm5519454\n",
       "7638147  tt9916852   nm5519375\n",
       "7638147  tt9916852   nm5519454\n",
       "7638148  tt9916856  nm10538645\n",
       "7638149  tt9916880   nm0996406"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directors = imdb_crew.explode('directors_list').drop(columns=['directors', 'writers'], inplace=False)\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.explode.html\n",
    "# this will create a new dataframe where each row is an individual director.  We drop the directors and \n",
    "# writers columns\n",
    "\n",
    "directors.rename(columns={\"directors_list\": \"director\"}, inplace = True) \n",
    "# rename the directors_list column to \"director\" since it's no longer a list\n",
    "\n",
    "directors.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the final directors dataframe by merging data from imbd_name, imdb_title_basics and imdb_ratings.  Print the number of shape of the dataframe before and after each merge: use a left merge (`how='left'`) so we can clean the dataframe appropriately later.\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original dataframe has a shape of (9018521, 2)\n",
      "After merging in data from the imdb_name dataframe, directors has a shape of (9018521, 3)\n",
      "After merging in data from the imdb_title_basics dataframe, directors has a shape of (9018521, 5)\n",
      "After merging in data from the imdb_ratings dataframe, directors has a shape of (9018521, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>director</th>\n",
       "      <th>primaryName</th>\n",
       "      <th>isTrueCrime</th>\n",
       "      <th>startYear</th>\n",
       "      <th>averageRating</th>\n",
       "      <th>numVotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9018516</th>\n",
       "      <td>tt9916850</td>\n",
       "      <td>nm5519454</td>\n",
       "      <td>Semih Bagci</td>\n",
       "      <td>False</td>\n",
       "      <td>2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9018517</th>\n",
       "      <td>tt9916852</td>\n",
       "      <td>nm5519375</td>\n",
       "      <td>Deniz Yorulmazer</td>\n",
       "      <td>False</td>\n",
       "      <td>2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9018518</th>\n",
       "      <td>tt9916852</td>\n",
       "      <td>nm5519454</td>\n",
       "      <td>Semih Bagci</td>\n",
       "      <td>False</td>\n",
       "      <td>2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9018519</th>\n",
       "      <td>tt9916856</td>\n",
       "      <td>nm10538645</td>\n",
       "      <td>Johan Planefeldt</td>\n",
       "      <td>False</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9018520</th>\n",
       "      <td>tt9916880</td>\n",
       "      <td>nm0996406</td>\n",
       "      <td>Hilary Audus</td>\n",
       "      <td>False</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            tconst    director       primaryName isTrueCrime startYear  \\\n",
       "9018516  tt9916850   nm5519454       Semih Bagci       False      2010   \n",
       "9018517  tt9916852   nm5519375  Deniz Yorulmazer       False      2010   \n",
       "9018518  tt9916852   nm5519454       Semih Bagci       False      2010   \n",
       "9018519  tt9916856  nm10538645  Johan Planefeldt       False      2015   \n",
       "9018520  tt9916880   nm0996406      Hilary Audus       False      2014   \n",
       "\n",
       "         averageRating  numVotes  \n",
       "9018516            NaN       NaN  \n",
       "9018517            NaN       NaN  \n",
       "9018518            NaN       NaN  \n",
       "9018519            NaN       NaN  \n",
       "9018520            NaN       NaN  "
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'The original dataframe has a shape of {directors.shape}')\n",
    "\n",
    "# Merge in the director's name and drop the redundant nconst field\n",
    "directors = pd.merge(directors, imdb_name[['nconst','primaryName']], left_on = 'director', right_on = 'nconst', how='left').drop(columns=['nconst'], inplace = False)\n",
    "print(f'After merging in data from the imdb_name dataframe, directors has a shape of {directors.shape}')\n",
    "\n",
    "# Merge in the IsTrueCrime field\n",
    "directors = pd.merge(directors, imdb_title_basics[['tconst','isTrueCrime', 'startYear']], on = 'tconst', how='left')\n",
    "print(f'After merging in data from the imdb_title_basics dataframe, directors has a shape of {directors.shape}')\n",
    "\n",
    "# Merge in the averageRating and numVotes fields\n",
    "directors = pd.merge(directors, imdb_ratings[['tconst','averageRating', 'numVotes']], on = 'tconst', how='left')\n",
    "print(f'After merging in data from the imdb_ratings dataframe, directors has a shape of {directors.shape}')\n",
    "\n",
    "directors.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Titles Cleanup - Step 3\n",
    "\n",
    "In this step we will focus on dropping nulls, uncessary columns, and uncessary values in the columns. \n",
    "\n",
    "First, we will create a working copy of the title basics called media_titles. Then we will remove the nulls for the titles and genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7634822, 10)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "media_titles = imdb_title_basics #Create new table for analysis\n",
    "media_titles.shape  #This is the original population size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>titleType</th>\n",
       "      <th>primaryTitle</th>\n",
       "      <th>originalTitle</th>\n",
       "      <th>isAdult</th>\n",
       "      <th>startYear</th>\n",
       "      <th>endYear</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>genres</th>\n",
       "      <th>isTrueCrime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1419373</th>\n",
       "      <td>tt10790040</td>\n",
       "      <td>tvEpisode</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3841497</th>\n",
       "      <td>tt1971246</td>\n",
       "      <td>tvEpisode</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2011</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>Biography</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3934048</th>\n",
       "      <td>tt2067043</td>\n",
       "      <td>tvEpisode</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1965</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>Music</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5099580</th>\n",
       "      <td>tt4404732</td>\n",
       "      <td>tvEpisode</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5708162</th>\n",
       "      <td>tt5773048</td>\n",
       "      <td>tvEpisode</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>Talk-Show</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6953493</th>\n",
       "      <td>tt8473688</td>\n",
       "      <td>tvEpisode</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>Drama</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6985205</th>\n",
       "      <td>tt8541336</td>\n",
       "      <td>tvEpisode</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>Reality-TV,Romance</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7590764</th>\n",
       "      <td>tt9824302</td>\n",
       "      <td>tvEpisode</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tconst  titleType primaryTitle originalTitle isAdult startYear  \\\n",
       "1419373  tt10790040  tvEpisode          NaN           NaN       0      2019   \n",
       "3841497   tt1971246  tvEpisode          NaN           NaN       0      2011   \n",
       "3934048   tt2067043  tvEpisode          NaN           NaN       0      1965   \n",
       "5099580   tt4404732  tvEpisode          NaN           NaN       0      2015   \n",
       "5708162   tt5773048  tvEpisode          NaN           NaN       0      2015   \n",
       "6953493   tt8473688  tvEpisode          NaN           NaN       0      1987   \n",
       "6985205   tt8541336  tvEpisode          NaN           NaN       0      2018   \n",
       "7590764   tt9824302  tvEpisode          NaN           NaN       0      2016   \n",
       "\n",
       "        endYear runtimeMinutes              genres  isTrueCrime  \n",
       "1419373      \\N             \\N                  \\N        False  \n",
       "3841497      \\N             \\N           Biography        False  \n",
       "3934048      \\N             \\N               Music        False  \n",
       "5099580      \\N             \\N              Comedy        False  \n",
       "5708162      \\N             \\N           Talk-Show        False  \n",
       "6953493      \\N             \\N               Drama        False  \n",
       "6985205      \\N             \\N  Reality-TV,Romance        False  \n",
       "7590764      \\N             \\N         Documentary        False  "
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_ptitles = media_titles[media_titles.primaryTitle.isnull()]\n",
    "null_ptitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>titleType</th>\n",
       "      <th>primaryTitle</th>\n",
       "      <th>originalTitle</th>\n",
       "      <th>isAdult</th>\n",
       "      <th>startYear</th>\n",
       "      <th>endYear</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>genres</th>\n",
       "      <th>isTrueCrime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1419373</th>\n",
       "      <td>tt10790040</td>\n",
       "      <td>tvEpisode</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3841497</th>\n",
       "      <td>tt1971246</td>\n",
       "      <td>tvEpisode</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2011</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>Biography</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3934048</th>\n",
       "      <td>tt2067043</td>\n",
       "      <td>tvEpisode</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1965</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>Music</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5099580</th>\n",
       "      <td>tt4404732</td>\n",
       "      <td>tvEpisode</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5708162</th>\n",
       "      <td>tt5773048</td>\n",
       "      <td>tvEpisode</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>Talk-Show</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6953493</th>\n",
       "      <td>tt8473688</td>\n",
       "      <td>tvEpisode</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>Drama</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6985205</th>\n",
       "      <td>tt8541336</td>\n",
       "      <td>tvEpisode</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>Reality-TV,Romance</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7590764</th>\n",
       "      <td>tt9824302</td>\n",
       "      <td>tvEpisode</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tconst  titleType primaryTitle originalTitle isAdult startYear  \\\n",
       "1419373  tt10790040  tvEpisode          NaN           NaN       0      2019   \n",
       "3841497   tt1971246  tvEpisode          NaN           NaN       0      2011   \n",
       "3934048   tt2067043  tvEpisode          NaN           NaN       0      1965   \n",
       "5099580   tt4404732  tvEpisode          NaN           NaN       0      2015   \n",
       "5708162   tt5773048  tvEpisode          NaN           NaN       0      2015   \n",
       "6953493   tt8473688  tvEpisode          NaN           NaN       0      1987   \n",
       "6985205   tt8541336  tvEpisode          NaN           NaN       0      2018   \n",
       "7590764   tt9824302  tvEpisode          NaN           NaN       0      2016   \n",
       "\n",
       "        endYear runtimeMinutes              genres  isTrueCrime  \n",
       "1419373      \\N             \\N                  \\N        False  \n",
       "3841497      \\N             \\N           Biography        False  \n",
       "3934048      \\N             \\N               Music        False  \n",
       "5099580      \\N             \\N              Comedy        False  \n",
       "5708162      \\N             \\N           Talk-Show        False  \n",
       "6953493      \\N             \\N               Drama        False  \n",
       "6985205      \\N             \\N  Reality-TV,Romance        False  \n",
       "7590764      \\N             \\N         Documentary        False  "
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_otitles = media_titles[media_titles.originalTitle.isnull()]\n",
    "null_otitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7634814, 10)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "media_titles = media_titles.drop(null_ptitles.index)  \n",
    "media_titles.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This only removed 8 titles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7634804, 10)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_genres = media_titles[media_titles.genres.isnull()]\n",
    "media_titles = media_titles.drop(null_genres.index)\n",
    "media_titles.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ended up removing 10 titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tconst            0\n",
       "titleType         0\n",
       "primaryTitle      0\n",
       "originalTitle     0\n",
       "isAdult           0\n",
       "startYear         0\n",
       "endYear           0\n",
       "runtimeMinutes    0\n",
       "genres            0\n",
       "isTrueCrime       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "media_titles.isnull().sum() #recheck and display the number of missing values in each column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reviewing the results, we noticied there are other values associated as null in our dataset like \\N. We will come back to address those. \n",
    "\n",
    "Now, we will drop the unnecessary columns for our analysis and merge in the average ratings and number of votes. We did not see use for if the title is for adults, what the end year is, the run time minutes, or what the original title was. This will drop 4 columns, but also add in 2 from the ratings dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7634804 entries, 0 to 7634821\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Dtype \n",
      "---  ------        ----- \n",
      " 0   tconst        object\n",
      " 1   titleType     object\n",
      " 2   primaryTitle  object\n",
      " 3   startYear     object\n",
      " 4   genres        object\n",
      " 5   isTrueCrime   bool  \n",
      "dtypes: bool(1), object(5)\n",
      "memory usage: 356.8+ MB\n"
     ]
    }
   ],
   "source": [
    "media_titles = media_titles.drop(columns=['isAdult','endYear','runtimeMinutes','originalTitle'], inplace=False)\n",
    "media_titles.info()                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7634804, 6)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "media_titles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the average ratings and votes\n",
    "media_titles = pd.merge(media_titles, imdb_ratings[['tconst','averageRating', 'numVotes']], on = 'tconst', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7634804 entries, 0 to 7634803\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Dtype  \n",
      "---  ------         -----  \n",
      " 0   tconst         object \n",
      " 1   titleType      object \n",
      " 2   primaryTitle   object \n",
      " 3   startYear      object \n",
      " 4   genres         object \n",
      " 5   isTrueCrime    bool   \n",
      " 6   averageRating  float64\n",
      " 7   numVotes       float64\n",
      "dtypes: bool(1), float64(2), object(5)\n",
      "memory usage: 473.3+ MB\n"
     ]
    }
   ],
   "source": [
    "media_titles.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will remove titles that are out of scope for analysis. We will not be looking at indivudal TV epsiodes, audiobooks, radio series', video games, or other episodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tvEpisode       5538841\n",
       "short            795153\n",
       "movie            568734\n",
       "video            295703\n",
       "tvSeries         201862\n",
       "tvMovie          130087\n",
       "tvMiniSeries      35957\n",
       "tvSpecial         31491\n",
       "videoGame         27373\n",
       "tvShort            9600\n",
       "episode               1\n",
       "audiobook             1\n",
       "radioSeries           1\n",
       "Name: titleType, dtype: int64"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "media_titles.titleType.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove tvEpisodes,videogame,radioSeries,audiobook,episode becasue they aren't relevant. For example, tvEpisode is just a subset of a tvSeries.\n",
    "\n",
    "indextype1 = media_titles[media_titles.titleType == 'episode'].index\n",
    "media_titles = media_titles.drop(indextype1)\n",
    "\n",
    "indextype2 = media_titles[media_titles.titleType == 'audiobook'].index\n",
    "media_titles = media_titles.drop(indextype2)\n",
    "\n",
    "indextype3 = media_titles[media_titles.titleType == 'radioSeries'].index\n",
    "media_titles = media_titles.drop(indextype3)\n",
    "\n",
    "indextype4 = media_titles[media_titles.titleType == 'videoGame'].index\n",
    "media_titles = media_titles.drop(indextype4)\n",
    "\n",
    "indextype5 = media_titles[media_titles.titleType == 'tvEpisode'].index\n",
    "media_titles = media_titles.drop(indextype5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_titles.titleType.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_titles.shape #From 7631524 to 2067987"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dropped 5,563,537 titles from our media titles dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Null Values & Duplicates - Step 4\n",
    "\n",
    "Now we will re-address the additional null values and check for duplciates. To account for them, we need to covert everything to null. We chose to drop all nulls from our directors and media_titles dataframes instead of imputing because after reviewing a sample of the data, a majority of the nulls were for title types that were not relevant to our analysis anyway. For example, TV episodes with missing directors. We also believe the most popular mainstream media is populated on IMDB which will be represented in our data analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# first convert '/N' to nulls. Then grab the total number of null values after coversion\n",
    "directors.shape # dataframe shape as a starting point\n",
    "((directors.isnull())).sum() # count of nulls we start with \n",
    "\n",
    "directors.replace(to_replace = '\\\\N', value = np.NaN, inplace=True) # replace all '/N' strings with NaN\n",
    "(directors.isnull()).sum() # we see the count of nulls increase\n",
    "\n",
    "directors.dropna(inplace=True) #drop all the rows with a null value (NaN)\n",
    "\n",
    "(directors.isnull()).sum() # we see the count of nulls go to zero\n",
    "directors.shape # we see a decrease from 9010972 rows to 1266176 due to all the missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our directors table, we deleted 7,744,796 rows that all had missing information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first convert '/N' to nulls as well. Then grab the total number of null values after coversion\n",
    "# titles table - conversion\n",
    "media_titles.shape # dataframe shape as a starting point\n",
    "((media_titles.isnull())).sum()# count of nulls we start with \n",
    "\n",
    "media_titles.replace(to_replace = '\\\\N', value = np.NaN, inplace=True) # replace all '/N' strings with NaN\n",
    "(media_titles.isnull()).sum() # we see the count of nulls increase\n",
    "\n",
    "media_titles.dropna(inplace=True) #drop all the rows with a null value (NaN)\n",
    "\n",
    "(media_titles.isnull()).sum() # we see the count of nulls go to zero\n",
    "media_titles.shape # we see a decrease from 2067987 rows to 576250 due to all the missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have 576,250 titles in our media_titles data set. We dropped 1,491,737 titles due to their missing data.\n",
    "\n",
    "Now, we will check for duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_titles.head()\n",
    "duplicate_media_titles = media_titles.duplicated('tconst')\n",
    "duplicate_media_titles.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directors.head()\n",
    "duplicate_dir_tconst = directors.duplicated(subset=['tconst'])\n",
    "duplicate_dir_tconst.value_counts() #313642 duplicate titles in the directors table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_dir_director = directors.duplicated(subset=['director'])\n",
    "duplicate_dir_director.value_counts() #1019989 duplicate directors in the directors table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_dir_both = directors.duplicated()\n",
    "duplicate_dir_both.value_counts() #no duplicate rows in directors table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were no duplicate titles in our media_titles dataset. As expected, we see duplicate titles in the directors dataset because a director can direct for multiple movies. Likewise, we see multiple titles because movies can have more than one director. However, we do not see any duplicate rows in the directors table.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop titles from the directors aren't that aren't in the media_titles dataframe\n",
    "\n",
    "We're using media_titles as our primary dataframe for analysis.  The directors dataframe should only include titles that are also included in our primary dataframe so any comparisons between the two are done on the same set of titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/3462143/get-difference-between-two-lists\n",
    "directors.shape\n",
    "director_titles = list(directors.tconst)\n",
    "media_titles_titles = list(media_titles.tconst)                      \n",
    "excess_director_titles = list(set(director_titles) - set(media_titles_titles)) \n",
    "# returns a list of title IDs that are in director_titles, but not in media_titles_titles\n",
    "len(excess_director_titles)  # tells us how many \"extra\" titles are in directors\n",
    "directors = directors[~directors.tconst.isin(excess_director_titles)] \n",
    "# returns a list of titles that are not in excess_director_titles\n",
    "directors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outliers and a Valid Number of Ratings based on Volatility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Outliers and Boxplots\n",
    "\n",
    "Boxplots don't tell us much about the data - higher numbers of votes appear as outliers, but these are actually values that are worth keeping.  There are many more titles with few votes than there are titles with many. See charts below.\n",
    "\n",
    "Similarly, boxplots on rating don't tell us much either - it's an ordinal scale that is useful for comparison, but we cannot tell anything concrete from the values themselves. In other words, we don't know anything about whether the differences in ratings actually correspond to anything meanful to the title they represent to actually be able to throw out outliers for the averageRating column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(directors.sample(n=10000, random_state=1), y=\"numVotes\", points=\"all\", title='Directors Boxplot - Number of Votes')\n",
    "fig.show()\n",
    "\n",
    "fig = px.box(media_titles_sample, y=\"numVotes\", points=\"all\", title='Media Titles Boxplot - Number of Votes')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Volatility and a minimum threshold for number of votes\n",
    "\n",
    "We expect volatility for the rating of a title to be high when the number of votes is low.  We measure volatility on a sample of the data to determine an approximate minimum threshold for the number of votes to assume a reliable rating.   \n",
    "\n",
    "Outliers on the other end of the numVotes column, i.e. movies with extremely high volumes of ratings, are not considered invalid - for this dataset we assume that the more rating there are, the better the averageRating.\n",
    "\n",
    "Helpful articles:\n",
    "1. https://www.bazaarvoice.com/blog/many-reviews-take-achieve-meaningful-average-rating/\n",
    "2. https://pbpython.com/pandas-qcut-cut.html <- if we wanted to split our dataframes into equal-sized quartiles instead of sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "media_titles['numVotes'].describe().apply(lambda x: format(x, 'f')) \n",
    "# describe the data (but not with scientific notation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "media_titles_sample = media_titles.sample(n=10000, random_state=1).copy()  # take a sample of the media titles dataframe\n",
    "media_titles_sample = media_titles_sample.sort_values(by=['numVotes']).set_index(['numVotes']) # sort the dataframe by the number of votes\n",
    "media_titles_sample['pct_change_rating'] = media_titles_sample.averageRating.pct_change() # caluculate a rolling percent change on the same\n",
    "# this will tell us for each subsequent row, how much the averageRating changed.  Higher values here indicate volatility\n",
    "media_titles_sample.reset_index(inplace=True)\n",
    "fig = px.line(media_titles_sample, x='numVotes', y='pct_change_rating', title='Rating Volatility by Number of Votes')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zooming in on the above chart roughly indicates that around 9000 votes is a good threshold to use.\n",
    "\n",
    "Therefore, we drop, in both the directors and media titles dataframes, any titles with less than 9000 votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before dropping titles with less than 9000 votes there were 733234 records in the directors dataframe\n",
      "After dropping titles with less than 9000 votes there were 0 records in the directors dataframe\n",
      "Before dropping titles with less than 9000 votes there were 563915 records in the directors dataframe\n",
      "After dropping titles with less than 9000 votes there were 0 records in the directors dataframe\n"
     ]
    }
   ],
   "source": [
    "directors_before = directors.shape\n",
    "print(f'Before dropping titles with less than 9000 votes there were {directors.shape[0]} records in the directors dataframe')\n",
    "directors = directors[directors['numVotes'] > 9000]\n",
    "print(f'After dropping titles with less than 9000 votes there were {directors.shape[0]} records in the directors dataframe')\n",
    "\n",
    "print(f'Before dropping titles with less than 9000 votes there were {media_titles.shape[0]} records in the directors dataframe')\n",
    "media_titles = media_titles[media_titles['numVotes'] > 9000]\n",
    "print(f'After dropping titles with less than 9000 votes there were {media_titles.shape[0]} records in the directors dataframe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"><b>STOP HERE for your EDA Phase 1 assignment. Submit your <i><u>cleaned</u></i> data file along with the completed notebook up to this point for grading.</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA Phase 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">All of your work for the EDA Phase 2 assignment will begin below here. Refer to the detailed instructions and expectations for this assignment in Canvas.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
